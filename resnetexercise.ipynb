{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercies has an implementation on an arbitrary length network defined by you the user. This network was written for \n",
    "$$ Y = w_n(cos(w_{n-1}*z_{n-1})) $$\n",
    "Where $$ z_{n-1} = (cos(w_{n-2}*z_{n-2})) $$\n",
    "starting with $z_0$\n",
    "This first block just initiallizes some random weights to train both the residual and nonresidual network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = 3.\n",
    "Y = 6.\n",
    "\n",
    "numnodes = 3\n",
    "\n",
    "eta = 1.0e-4\n",
    "\n",
    "nodeval = np.random.rand(numnodes)\n",
    "nodeval[0] = X\n",
    "\n",
    "weights = np.random.rand(numnodes-1)\n",
    "nodegrad = np.random.rand(numnodes-1)\n",
    "bias = np.random.rand(numnodes-1)\n",
    "\n",
    "nodeval_1 = nodeval + 0\n",
    "weights_1 = weights + 0\n",
    "nodegrad_1 = nodegrad + 0\n",
    "bias_1 = nodegrad + 0 \n",
    "\n",
    "nodeval_res = nodeval + 0\n",
    "weights_res = weights + 0\n",
    "nodegrad_res = nodegrad + 0\n",
    "bias_res = bias + 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines forward and backward modes for these derivatives. I'm about 80 percent sure this is right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(nodes, weights, bias):\n",
    "\n",
    "    for i in range(len(nodes)-2):\n",
    "        nodenext = np.sin(weights[i]*nodes[i]+bias[i])\n",
    "        nodes[i+1] = nodenext\n",
    "    \n",
    "        grad = np.cos(weights[i]*nodes[i])*weights[i]\n",
    "        nodegrad[i+1] = grad\n",
    "    \n",
    "    nodes[-1] = weights[-1]*nodes[-2] + bias[-1]\n",
    "    nodegrad[-1] = weights[-1]\n",
    "    \n",
    "    return nodes, nodegrad\n",
    "\n",
    "\n",
    "def backward(nodes, weights, bias, nodegrad, seed):\n",
    "    \n",
    "    gradientw = []\n",
    "    gradientb = []\n",
    "    \n",
    "    gradienttot = seed\n",
    "    gradientw.append(gradienttot*nodes[-2])\n",
    "    gradientb.append(gradienttot)\n",
    "    \n",
    "    for i in range(len(nodegrad)-1):\n",
    "        gradienttot *= nodegrad[-(i+2)]\n",
    "        gradientw.append(gradienttot*nodes[-(3+i)]*np.cos(nodes[-(3+i)]*weights[-(2+i)]))\n",
    "        gradientb.append(gradienttot*nodes[-(3+i)]*np.cos(nodes[-(3+i)]*weights[-(2+i)])+bias[-(2+i)])\n",
    "        \n",
    "    gradientw = np.array(gradientw)\n",
    "    gradientb = np.array(gradientb)\n",
    "    \n",
    "    return gradientw[::-1], gradientb[::-1]\n",
    "\n",
    "def dL(out, target):\n",
    "    L = (out - target)**2\n",
    "    dL = 2*(out - target)\n",
    "    return L, dL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.309553405035324\n",
      "0.13857684422328628\n",
      "0.16950202566059522\n",
      "0.09672454201713003\n",
      "0.029090353288521872\n",
      "0.005969590392474782\n",
      "0.0009942058371652856\n",
      "0.00014863967069778908\n",
      "2.1065433184401035e-05\n",
      "2.910388933219156e-06\n",
      "[3.00000000e+00 8.81896503e-01 7.19620158e-01 9.66389971e-01\n",
      " 5.07635547e-01 3.00403683e-01 5.49500573e-01 9.30818717e-01\n",
      " 5.20761437e-01 2.67207032e-01 8.77398789e-01 3.71918749e-01\n",
      " 1.38335000e-03 2.47685022e-01 3.18233509e-01 8.58777468e-01\n",
      " 4.58503167e-01 4.44587288e-01 3.36102266e-01 8.80678123e-01\n",
      " 9.45026777e-01 9.91890329e-01 3.76741267e-01 9.66147446e-01\n",
      " 7.91879570e-01 6.75689148e-01 2.44889479e-01 2.16457261e-01\n",
      " 1.66047825e-01 9.22756610e-01]\n",
      "[3.00000000e+00 7.72181139e-01 3.42806694e-01 1.68566682e-01\n",
      " 1.30813786e-01 1.10253701e-01 1.53676176e-02 6.57667612e-03\n",
      " 5.57136707e-03 4.57064372e-03 5.07778598e-04 8.45102686e-05\n",
      " 3.53485610e-05 1.09702102e-05 2.29486774e-05 3.62897026e-05\n",
      " 4.45325456e-05 3.31126617e-05 1.97758223e-05 2.16332050e-05\n",
      " 2.40024382e-05 3.18986670e-05 5.49062713e-05 2.32703920e-05\n",
      " 4.49643096e-05 5.98263281e-05 1.88583821e-05 4.34936492e-05\n",
      " 1.86368429e-04 5.99936952e+00]\n",
      "Target =  6.0  Guess =  5.999369581167667\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    nodeval_1, nodegrad_1 = forward(nodeval_1, weights_1, bias_1)\n",
    "    \n",
    "    loss, lossgrad = dL(nodeval_1[-1], Y)\n",
    "    \n",
    "    gradientsw, gradientsb = backward(nodeval_1, weights_1, bias_1, nodegrad_1, lossgrad)\n",
    "    \n",
    "    weights_1 -= gradientsw*eta\n",
    "    bias_1 -= gradientsb*eta\n",
    "    \n",
    "    if i%10000 == 0:\n",
    "        print(loss)\n",
    "    \n",
    "print(nodeval)\n",
    "print(nodeval_1)\n",
    "nodeval_1, nodegrad_1 = forward(nodeval_1, weights_1, bias_1)\n",
    "print('Target = ', Y, ' Guess = ', nodeval_1[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that isn't the best. Let's try a residual implementation where $$ Y = w_n(cos(w_{n-1}*z_{n-1})) + z_{n-1}$$\n",
    "Where $$ z_{n-1} = (cos(w_{n-2}*z_{n-2})) + z_{n-2} $$\n",
    "starting with $z_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_res(nodes, weights, bias):\n",
    "\n",
    "    for i in range(len(nodes)-2):\n",
    "        nodenext = np.sin(weights[i]*nodes[i]+bias[i]) + nodes[i]\n",
    "        nodes[i+1] = nodenext\n",
    "    \n",
    "        grad = np.cos(weights[i]*nodes[i])*weights[i] + 1\n",
    "        nodegrad[i+1] = grad\n",
    "    \n",
    "    nodes[-1] = weights[-1]*nodes[-2] + nodes[-2] + bias[-1]\n",
    "    nodegrad[-1] = weights[-1] + 1\n",
    "    \n",
    "    \n",
    "    return nodes, nodegrad\n",
    "\n",
    "\n",
    "def backward_res(nodes, weights, bias, nodegrad, seed):\n",
    "    \n",
    "    gradientw = []\n",
    "    gradientb = []\n",
    "    \n",
    "    gradienttot = seed\n",
    "    gradientw.append(gradienttot*nodes[-2])\n",
    "    gradientb.append(gradienttot)\n",
    "    \n",
    "    for i in range(len(nodegrad)-1):\n",
    "        gradienttot *= nodegrad[-(i+2)]\n",
    "        gradientw.append(gradienttot*nodes[-(3+i)]*np.cos(nodes[-(3+i)]*weights[-(2+i)]))\n",
    "        gradientb.append(gradienttot*nodes[-(3+i)]*np.cos(nodes[-(3+i)]*weights[-(2+i)])+bias[-(2+i)])\n",
    "        \n",
    "    gradientw = np.array(gradientw)\n",
    "    gradientb = np.array(gradientb)\n",
    "    \n",
    "    return gradientw[::-1], gradientb[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.720854886672477\n",
      "4.645174036892062e-05\n",
      "5.815911595448678e-06\n",
      "8.251133774849137e-07\n",
      "1.2405929668301923e-07\n",
      "1.9101953333487257e-08\n",
      "2.9694566019575477e-09\n",
      "4.6337951146018647e-10\n",
      "7.242031581917943e-11\n",
      "1.1325286136131894e-11\n",
      "[3.00000000e+00 8.81896503e-01 7.19620158e-01 9.66389971e-01\n",
      " 5.07635547e-01 3.00403683e-01 5.49500573e-01 9.30818717e-01\n",
      " 5.20761437e-01 2.67207032e-01 8.77398789e-01 3.71918749e-01\n",
      " 1.38335000e-03 2.47685022e-01 3.18233509e-01 8.58777468e-01\n",
      " 4.58503167e-01 4.44587288e-01 3.36102266e-01 8.80678123e-01\n",
      " 9.45026777e-01 9.91890329e-01 3.76741267e-01 9.66147446e-01\n",
      " 7.91879570e-01 6.75689148e-01 2.44889479e-01 2.16457261e-01\n",
      " 1.66047825e-01 9.22756610e-01]\n",
      "[3.00000000e+00 7.72181137e-01 3.42806690e-01 1.68566676e-01\n",
      " 1.30813780e-01 1.10253692e-01 1.53676128e-02 6.57667244e-03\n",
      " 5.57136115e-03 4.57063757e-03 5.07774001e-04 8.45090393e-05\n",
      " 3.53472230e-05 1.09692787e-05 2.29464528e-05 3.62860812e-05\n",
      " 4.45280967e-05 3.31093515e-05 1.97738453e-05 2.16310417e-05\n",
      " 2.40000380e-05 3.18954772e-05 5.49007807e-05 2.32680650e-05\n",
      " 4.49598132e-05 5.98203455e-05 1.88564965e-05 4.34893001e-05\n",
      " 1.86349796e-04 5.99936958e+00]\n",
      "Target =  6.0  Guess =  6.000001330981228\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    nodeval_res, nodegrad_res = forward_res(nodeval_res, weights_res, bias_res)\n",
    "    \n",
    "    loss, lossgrad = dL(nodeval_res[-1], Y)\n",
    "\n",
    "    gradientsw, gradientsb = backward_res(nodeval_res, weights_res, bias_res, nodegrad_res, lossgrad)\n",
    "    \n",
    "    weights_res -= gradientsw*eta\n",
    "    bias_res -= gradientsb*eta\n",
    "    \n",
    "    if i%10000 == 0:\n",
    "        print(loss)\n",
    "        \n",
    "print(nodeval)\n",
    "print(nodeval_1)\n",
    "nodeval_res, nodegrad_res = forward_res(nodeval_res, weights_res, bias_res)\n",
    "print('Target = ', Y, ' Guess = ', nodeval_res[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = np.linspace(0, 60, 1000)\n",
    "empty = np.zeros(numnodes)\n",
    "values = []\n",
    "\n",
    "for i in check:\n",
    "    empty[0] = i\n",
    "    n, g = forward_res(empty, weights_res, bias_res)\n",
    "    values.append(n[-1])\n",
    "\n",
    "plt.plot(check, values)\n",
    "\n",
    "values = []\n",
    "\n",
    "for i in check:\n",
    "    empty[0] = i\n",
    "    n, g = forward(empty, weights_1, bias_1)\n",
    "    values.append(n[-1])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(check, values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming, I implemented this correctly, just increadible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was trying to get this to work with T-money's autodiff, but was failing. It would be more general and fun if we can get it working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Constant:\n",
    "    \n",
    "    def __init__(self, a):\n",
    "        # Initialize the value of this variable with the value passed in\n",
    "        self.a_value = a\n",
    "        # to make sure our children don't throw an exception when they access our grad variable \n",
    "        # as in backward() in the BinaryAdd()\n",
    "        self.grad = 0\n",
    "    \n",
    "    def forward(self):\n",
    "        # what should this return?\n",
    "        # TODO: fill in the return value\n",
    "        # Remember this is the last node of the graph.\n",
    "        return self.a_value\n",
    "    \n",
    "    def backward(self):\n",
    "        # What should go here if it's a constant?\n",
    "        # Nothing. We want the backpropagation to stop here. \n",
    "        # In python, we use pass as shorthand for \"return None\".\n",
    "        # Doing this means we can inject constants at any point in the computational graph.\n",
    "        pass\n",
    "\n",
    "class BinaryAdd:\n",
    "    \n",
    "    def __init__(self, a, b):\n",
    "        # record the two parents of the binary add\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        # and initialize the gradient to 0.\n",
    "        self.grad = 0\n",
    "        \n",
    "    def forward(self):\n",
    "        # a _value and b_value\n",
    "        # are intermediate values in the computational graph\n",
    "        # like v4 in Table 3 in the paper.\n",
    "        # We don't have to store the value of a or b, \n",
    "        # but caching them now means we don't have to recompute them on the backward pass.\n",
    "        self.a_value = self.a.forward()\n",
    "        self.b_value = self.b.forward()\n",
    "        return self.a_value + self.b_value\n",
    "    \n",
    "    def backward(self):\n",
    "        # z = a + b\n",
    "        # dz/da = ?\n",
    "        # TODO: fill in the None values.\n",
    "        # Remember, a and b are the parents of this object. \n",
    "        dzda = 1\n",
    "        dzdb = 1\n",
    "        self.a.grad += dzda*self.grad\n",
    "        self.b.grad += dzdb*self.grad\n",
    "\n",
    "class BinaryMul:\n",
    "    \n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.grad = 0\n",
    "        # TODO: what's missing? What other value do we have to store in a node?\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        # again, we don't have to cache self.a_value or self.b_value\n",
    "        # but it makes the backward pass not have to call a.forward() or b.forward()\n",
    "        # TODO: fill in None\n",
    "        self.a_value = self.a.forward()\n",
    "        self.b_value = self.b.forward()\n",
    "        return self.a_value * self.b_value\n",
    "\n",
    "    def backward(self):\n",
    "        # TODO: fill in the gradient values below (dzda, dzdb)\n",
    "        # z = a*b \n",
    "        # dz/da = ?\n",
    "        dzda = self.b_value\n",
    "        dzdb = self.a_value\n",
    "        self.a.grad += dzda*self.grad\n",
    "        self.b.grad += dzdb*self.grad\n",
    "        \n",
    "class Ln:\n",
    "    \n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "        self.grad = 0\n",
    "\n",
    "    def forward(self):\n",
    "        # TODO: fill me in\n",
    "        self.a_value = self.a.forward()\n",
    "        return np.log(self.a_value)\n",
    "    \n",
    "    def backward(self):\n",
    "        # TODO: fill me in\n",
    "        # z = ln(a)\n",
    "        # dz/da = ?\n",
    "        self.a.grad += 1/self.a_value*self.grad\n",
    "\n",
    "        \n",
    "class Sin:\n",
    "    \n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "        self.grad = 0\n",
    "        \n",
    "    def forward(self):\n",
    "        # TODO: fill me in\n",
    "        self.a_value = self.a.forward()\n",
    "        return np.sin(self.a_value)\n",
    "    \n",
    "    def backward(self):\n",
    "        # TODO: fill me in \n",
    "        # z = sin(a)\n",
    "        # dz/da = ?\n",
    "        self.a.grad += np.cos(self.a_value)*self.grad\n",
    "\n",
    "\n",
    "class BinarySub:\n",
    "    \n",
    "    def __init__(self, a, b):\n",
    "        # TODO:\n",
    "        # record the two parents of the binary subtract\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        # and initialize the gradient to 0.\n",
    "        self.grad = 0\n",
    "        \n",
    "    def forward(self):\n",
    "        # TODO: How do I get a and b?\n",
    "        self.a_value = self.a.forward()\n",
    "        self.b_value = self.b.forward()\n",
    "        return self.a_value - self.b_value\n",
    "    \n",
    "    def backward(self):\n",
    "        # z = a - b\n",
    "        # dz/da = ?\n",
    "        # TODO: fill in the None values.\n",
    "        # Remember, a and b are the parents of this object. \n",
    "        dzda = 1\n",
    "        dzdb = -1\n",
    "        self.a.grad += dzda*self.grad\n",
    "        self.b.grad += dzdb*self.grad  # Why is this a += operator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: -0.9785235488295365\n"
     ]
    }
   ],
   "source": [
    "X = Constant(3)\n",
    "Y = 2.\n",
    "\n",
    "w1 = Constant(.4)\n",
    "w2 = Constant(.1)\n",
    "\n",
    "v1 = BinaryMul(X, w1)\n",
    "v2 = Sin(v1)\n",
    "v3 = BinaryMul(v2, w2)\n",
    "\n",
    "eta = 1.0e-5\n",
    "\n",
    "for i in range(100000):\n",
    "\n",
    "    y = v3.forward()\n",
    "    \n",
    "    #print('y: {}'.format(y))\n",
    "    #print(.5*np.sin(.4*4))\n",
    "\n",
    "    # TODO: seed the gradient value\n",
    "    v3.grad = 2*(y - Y) \n",
    "    v3.backward()\n",
    "\n",
    "    # Instead of calling backward() on each node by hand, put the nodes in \n",
    "    # a list and iterate over it backwards.\n",
    "\n",
    "    ls = [X, w1, v1, v2, w2]\n",
    "\n",
    "    for node in ls[::-1]:\n",
    "        #print(node.grad)\n",
    "        node.backward()\n",
    "    \n",
    "    w1.a_value -= w1.grad*eta\n",
    "    w2.a_value -= w2.grad*eta\n",
    "\n",
    "print('y: {}'.format(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (9,9)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,layers, input_size, num_class):\n",
    "        super(Net, self).__init__()\n",
    "        self.input = input_size\n",
    "        self.classes = num_class\n",
    "        self.layers = layers\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input,self.input)])\n",
    "        self.linears.extend([nn.Linear(self.input, self.input) for i in range(1, self.layers-1)])\n",
    "        self.linears.append(nn.Linear(self.input, self.classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        temp = None\n",
    "        i = 0\n",
    "        for layer in self.linears:\n",
    "            if i%3 == 0:\n",
    "                x = torch.sigmoid(layer(x))\n",
    "                i += 1\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                i += 1\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784       # The image size = 28 x 28 = 784\n",
    "num_classes = 10       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 100       # The size of input data took for one iteration\n",
    "learning_rate = 1e-3  # The speed of convergence\n",
    "net = Net(10, input_size,num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(nn.ParameterList(net.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.3143715858459473 10.279999732971191\n",
      "1 2.302456855773926 11.350000381469727\n",
      "2 2.3005683422088623 11.350000381469727\n",
      "3 2.2983646392822266 11.350000381469727\n",
      "4 2.2984426021575928 11.350000381469727\n",
      "5 2.316406726837158 11.350000381469727\n",
      "6 2.3070859909057617 11.350000381469727\n",
      "7 2.293673038482666 11.350000381469727\n",
      "8 2.3094537258148193 10.279999732971191\n",
      "9 2.2959601879119873 11.350000381469727\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = Variable(images.view(-1,28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = Variable(labels)\n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()\n",
    "    total=0\n",
    "    correct=0\n",
    "    # Loop over all the test examples and accumulate the number of correct results in each batch\n",
    "    for d,t in test_loader:\n",
    "        outputs = net(d.view(-1,28*28))\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += Variable(t).size(0)\n",
    "        correct += (predicted==t).sum()\n",
    "        \n",
    "    # Print the epoch, the training loss, and the test set accuracy.\n",
    "    print(epoch,loss.item(),(100.*correct/total).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resNet(nn.Module):\n",
    "    def __init__(self,layers, input_size, num_class):\n",
    "        super(resNet, self).__init__()\n",
    "        self.input = input_size\n",
    "        self.classes = num_class\n",
    "        self.layers = layers\n",
    "        self.linears = nn.ModuleList([nn.Linear(self.input,self.input)])\n",
    "        self.linears.extend([nn.Linear(self.input, self.input) for i in range(1, self.layers-1)])\n",
    "        self.linears.append(nn.Linear(self.input, self.classes))\n",
    "    def forward(self, x):\n",
    "        temp = x\n",
    "        i = 0\n",
    "        for layer in self.linears:\n",
    "            print(layer(x))\n",
    "            if i%3 == 0:\n",
    "                x = torch.sigmoid(layer(x))\n",
    "                i += 1\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                i += 1\n",
    "        print(x.shape, temp.shape)\n",
    "        return x + temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784       # The image size = 28 x 28 = 784\n",
    "num_classes = 10       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 100       # The size of input data took for one iteration\n",
    "learning_rate = 1e-3  # The speed of convergence\n",
    "resnet = resNet(10, input_size,num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(nn.ParameterList(net.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0603, -0.2374, -0.2596,  ..., -0.0049, -0.0785,  0.1213],\n",
      "        [ 0.0942,  0.3139,  0.1319,  ...,  0.0852,  0.2276,  0.1503],\n",
      "        [-0.1532,  0.4307,  0.0131,  ...,  0.1803,  0.0502,  0.3117],\n",
      "        ...,\n",
      "        [ 0.2572,  0.1046, -0.0641,  ..., -0.0265,  0.0656,  0.1438],\n",
      "        [-0.1443, -0.0782, -0.0690,  ...,  0.2466, -0.0380, -0.2145],\n",
      "        [ 0.0371,  0.3303, -0.0805,  ...,  0.1398, -0.0016,  0.3181]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2547,  0.3964, -0.0981,  ...,  0.3998,  0.0472,  0.4862],\n",
      "        [ 0.2870,  0.4213, -0.1102,  ...,  0.4171,  0.0543,  0.4647],\n",
      "        [ 0.2867,  0.4680, -0.1283,  ...,  0.3914,  0.0279,  0.5167],\n",
      "        ...,\n",
      "        [ 0.2586,  0.4255, -0.0690,  ...,  0.4227,  0.0383,  0.4575],\n",
      "        [ 0.2364,  0.4134, -0.1002,  ...,  0.3563,  0.0842,  0.4902],\n",
      "        [ 0.2969,  0.4835, -0.1125,  ...,  0.4052,  0.0309,  0.4820]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2523,  0.4345,  0.0059,  ..., -0.1859, -0.0016, -0.1131],\n",
      "        [ 0.2739,  0.4161, -0.0037,  ..., -0.1653, -0.0163, -0.1400],\n",
      "        [ 0.2777,  0.4486, -0.0034,  ..., -0.1966,  0.0061, -0.1267],\n",
      "        ...,\n",
      "        [ 0.2682,  0.4348,  0.0168,  ..., -0.1503, -0.0130, -0.1156],\n",
      "        [ 0.2620,  0.4338,  0.0119,  ..., -0.1736,  0.0291, -0.1475],\n",
      "        [ 0.2971,  0.4526, -0.0029,  ..., -0.1705,  0.0165, -0.1348]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0088,  0.0203,  0.0949,  ..., -0.0391,  0.1194, -0.0668],\n",
      "        [-0.0270,  0.0192,  0.0955,  ..., -0.0296,  0.1337, -0.0751],\n",
      "        [-0.0146,  0.0211,  0.1191,  ..., -0.0420,  0.1226, -0.0583],\n",
      "        ...,\n",
      "        [-0.0168,  0.0195,  0.0818,  ..., -0.0339,  0.1275, -0.0698],\n",
      "        [-0.0104,  0.0324,  0.0926,  ..., -0.0389,  0.1172, -0.0629],\n",
      "        [-0.0284,  0.0148,  0.1036,  ..., -0.0335,  0.1253, -0.0650]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4002,  0.4940,  0.1087,  ..., -0.0360,  0.3859, -0.1391],\n",
      "        [ 0.3999,  0.4954,  0.1074,  ..., -0.0360,  0.3850, -0.1392],\n",
      "        [ 0.4010,  0.4935,  0.1088,  ..., -0.0348,  0.3858, -0.1392],\n",
      "        ...,\n",
      "        [ 0.3988,  0.4947,  0.1078,  ..., -0.0370,  0.3869, -0.1395],\n",
      "        [ 0.4012,  0.4933,  0.1073,  ..., -0.0369,  0.3867, -0.1398],\n",
      "        [ 0.4018,  0.4927,  0.1082,  ..., -0.0380,  0.3870, -0.1397]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0094, -0.0067, -0.0439,  ...,  0.0250,  0.1100,  0.1977],\n",
      "        [-0.0086, -0.0075, -0.0418,  ...,  0.0247,  0.1101,  0.1982],\n",
      "        [-0.0099, -0.0060, -0.0434,  ...,  0.0254,  0.1090,  0.1967],\n",
      "        ...,\n",
      "        [-0.0091, -0.0082, -0.0420,  ...,  0.0254,  0.1107,  0.1979],\n",
      "        [-0.0084, -0.0061, -0.0437,  ...,  0.0258,  0.1092,  0.1978],\n",
      "        [-0.0090, -0.0059, -0.0437,  ...,  0.0261,  0.1102,  0.1981]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1231,  0.0941, -0.1110,  ..., -0.2785,  0.0304,  0.0944],\n",
      "        [ 0.1235,  0.0932, -0.1110,  ..., -0.2793,  0.0308,  0.0945],\n",
      "        [ 0.1235,  0.0939, -0.1106,  ..., -0.2780,  0.0294,  0.0950],\n",
      "        ...,\n",
      "        [ 0.1228,  0.0938, -0.1113,  ..., -0.2796,  0.0308,  0.0949],\n",
      "        [ 0.1230,  0.0937, -0.1105,  ..., -0.2784,  0.0302,  0.0948],\n",
      "        [ 0.1233,  0.0930, -0.1110,  ..., -0.2789,  0.0299,  0.0956]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2688, -0.2011, -0.5498,  ...,  0.2207, -0.1673,  0.0115],\n",
      "        [ 0.2687, -0.2011, -0.5499,  ...,  0.2206, -0.1673,  0.0115],\n",
      "        [ 0.2687, -0.2011, -0.5498,  ...,  0.2207, -0.1673,  0.0115],\n",
      "        ...,\n",
      "        [ 0.2688, -0.2012, -0.5499,  ...,  0.2206, -0.1673,  0.0115],\n",
      "        [ 0.2687, -0.2011, -0.5498,  ...,  0.2207, -0.1673,  0.0115],\n",
      "        [ 0.2686, -0.2011, -0.5499,  ...,  0.2207, -0.1674,  0.0115]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2137, -0.0904, -0.0042,  ...,  0.1073,  0.0867, -0.1064],\n",
      "        [-0.2137, -0.0904, -0.0042,  ...,  0.1074,  0.0867, -0.1063],\n",
      "        [-0.2137, -0.0904, -0.0042,  ...,  0.1073,  0.0867, -0.1064],\n",
      "        ...,\n",
      "        [-0.2137, -0.0905, -0.0042,  ...,  0.1074,  0.0867, -0.1064],\n",
      "        [-0.2137, -0.0904, -0.0042,  ...,  0.1072,  0.0867, -0.1064],\n",
      "        [-0.2137, -0.0904, -0.0042,  ...,  0.1073,  0.0867, -0.1063]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0922],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0922],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0577, -0.0393, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0393, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0577, -0.0393, -0.0785, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1004,  0.0922],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1010,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1004,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0453,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0922],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0393, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0393, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0922],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0922],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0830, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0922],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0577, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921],\n",
      "        [-0.1097, -0.0831, -0.1010,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0922],\n",
      "        [-0.1097, -0.0831, -0.1011,  0.0460, -0.0576, -0.0394, -0.0784, -0.0452,\n",
      "         -0.1003,  0.0921]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([100, 10]) torch.Size([100, 784])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (784) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2b75e7a44a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# Intialize the hidden weight to all zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# Forward pass: compute the output class given a image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# Compute the loss: difference between the output class and the pre-given label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                   \u001b[0;31m# Backward pass: compute the weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/my_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-b31b61dc25cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (784) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = Variable(images.view(-1,28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = Variable(labels)\n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = resnet(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()\n",
    "    total=0\n",
    "    correct=0\n",
    "    # Loop over all the test examples and accumulate the number of correct results in each batch\n",
    "    for d,t in test_loader:\n",
    "        outputs = net(d.view(-1,28*28))\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        total += Variable(t).size(0)\n",
    "        correct += (predicted==t).sum()\n",
    "        \n",
    "    # Print the epoch, the training loss, and the test set accuracy.\n",
    "    print(epoch,loss.item(),(100.*correct/total).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
